# GENETARED BY NNDCT, DO NOT EDIT!

import torch
from torch import tensor
import pytorch_nndct as py_nndct

class Generator(py_nndct.nn.NndctQuantModel):
    def __init__(self):
        super(Generator, self).__init__()
        self.module_0 = py_nndct.nn.Input() #Generator::input_0(Generator::nndct_input_0)
        self.module_1 = py_nndct.nn.Input() #Generator::input_1(Generator::nndct_input_1)
        self.module_2 = py_nndct.nn.Linear(in_features=100, out_features=6400, bias=True) #Generator::Generator/Linear[net_noise]/ret.5(Generator::nndct_dense_2)
        self.module_3 = py_nndct.nn.Module('nndct_reshape') #Generator::Generator/ret.7(Generator::nndct_reshape_3)
        self.module_4 = py_nndct.nn.Linear(in_features=4, out_features=1024, bias=True) #Generator::Generator/Sequential[net_label]/Linear[0]/ret.9(Generator::nndct_dense_4)
        self.module_5 = py_nndct.nn.Module('aten::unflatten') #Generator::Generator/Sequential[net_label]/Unflatten[1]/ret.11(Generator::aten_unflatten_5)
        self.module_6 = py_nndct.nn.Module('aten::hstack') #Generator::Generator/ret.13(Generator::aten_hstack_6)
        self.module_7 = py_nndct.nn.ConvTranspose2d(in_channels=116, out_channels=64, kernel_size=[5, 5], stride=[2, 2], padding=[2, 2], output_padding=[1, 1], groups=1, bias=True, dilation=[1, 1]) #Generator::Generator/Sequential[net]/ConvTranspose2d[0]/ret.15(Generator::nndct_conv_transpose_2d_7)
        self.module_8 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/LeakyReLU[1]/ret.17(Generator::nndct_leaky_relu_8)
        self.module_9 = py_nndct.nn.Module('aten::_convolution_mode') #Generator::Generator/Sequential[net]/ResBlock[2]/Sequential[block]/Conv2d[0]/ret.19(Generator::aten__convolution_mode_9)
        self.module_10 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/ResBlock[2]/Sequential[block]/LeakyReLU[1]/ret.21(Generator::nndct_leaky_relu_10)
        self.module_11 = py_nndct.nn.Module('aten::_convolution_mode') #Generator::Generator/Sequential[net]/ResBlock[2]/Sequential[block]/Conv2d[2]/ret.23(Generator::aten__convolution_mode_11)
        self.module_12 = py_nndct.nn.Add() #Generator::Generator/Sequential[net]/ResBlock[2]/ret.25(Generator::nndct_elemwise_add_12)
        self.module_13 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/ResBlock[2]/LeakyReLU[leakyrelu]/ret.27(Generator::nndct_leaky_relu_13)
        self.module_14 = py_nndct.nn.ConvTranspose2d(in_channels=64, out_channels=128, kernel_size=[5, 5], stride=[2, 2], padding=[2, 2], output_padding=[1, 1], groups=1, bias=True, dilation=[1, 1]) #Generator::Generator/Sequential[net]/ConvTranspose2d[3]/ret.29(Generator::nndct_conv_transpose_2d_14)
        self.module_15 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/LeakyReLU[4]/ret.31(Generator::nndct_leaky_relu_15)
        self.module_16 = py_nndct.nn.Module('aten::_convolution_mode') #Generator::Generator/Sequential[net]/ResBlock[5]/Sequential[block]/Conv2d[0]/ret.33(Generator::aten__convolution_mode_16)
        self.module_17 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/ResBlock[5]/Sequential[block]/LeakyReLU[1]/ret.35(Generator::nndct_leaky_relu_17)
        self.module_18 = py_nndct.nn.Module('aten::_convolution_mode') #Generator::Generator/Sequential[net]/ResBlock[5]/Sequential[block]/Conv2d[2]/ret.37(Generator::aten__convolution_mode_18)
        self.module_19 = py_nndct.nn.Add() #Generator::Generator/Sequential[net]/ResBlock[5]/ret.39(Generator::nndct_elemwise_add_19)
        self.module_20 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/ResBlock[5]/LeakyReLU[leakyrelu]/ret.41(Generator::nndct_leaky_relu_20)
        self.module_21 = py_nndct.nn.ConvTranspose2d(in_channels=128, out_channels=256, kernel_size=[5, 5], stride=[2, 2], padding=[2, 2], output_padding=[1, 1], groups=1, bias=True, dilation=[1, 1]) #Generator::Generator/Sequential[net]/ConvTranspose2d[6]/ret.43(Generator::nndct_conv_transpose_2d_21)
        self.module_22 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/LeakyReLU[7]/ret.45(Generator::nndct_leaky_relu_22)
        self.module_23 = py_nndct.nn.Module('aten::_convolution_mode') #Generator::Generator/Sequential[net]/ResBlock[8]/Sequential[block]/Conv2d[0]/ret.47(Generator::aten__convolution_mode_23)
        self.module_24 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/ResBlock[8]/Sequential[block]/LeakyReLU[1]/ret.49(Generator::nndct_leaky_relu_24)
        self.module_25 = py_nndct.nn.Module('aten::_convolution_mode') #Generator::Generator/Sequential[net]/ResBlock[8]/Sequential[block]/Conv2d[2]/ret.51(Generator::aten__convolution_mode_25)
        self.module_26 = py_nndct.nn.Add() #Generator::Generator/Sequential[net]/ResBlock[8]/ret.53(Generator::nndct_elemwise_add_26)
        self.module_27 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/ResBlock[8]/LeakyReLU[leakyrelu]/ret.55(Generator::nndct_leaky_relu_27)
        self.module_28 = py_nndct.nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=[5, 5], stride=[2, 2], padding=[2, 2], output_padding=[1, 1], groups=1, bias=True, dilation=[1, 1]) #Generator::Generator/Sequential[net]/ConvTranspose2d[9]/ret.57(Generator::nndct_conv_transpose_2d_28)
        self.module_29 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/LeakyReLU[10]/ret.59(Generator::nndct_leaky_relu_29)
        self.module_30 = py_nndct.nn.Module('aten::_convolution_mode') #Generator::Generator/Sequential[net]/ResBlock[11]/Sequential[block]/Conv2d[0]/ret.61(Generator::aten__convolution_mode_30)
        self.module_31 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/ResBlock[11]/Sequential[block]/LeakyReLU[1]/ret.63(Generator::nndct_leaky_relu_31)
        self.module_32 = py_nndct.nn.Module('aten::_convolution_mode') #Generator::Generator/Sequential[net]/ResBlock[11]/Sequential[block]/Conv2d[2]/ret.65(Generator::aten__convolution_mode_32)
        self.module_33 = py_nndct.nn.Add() #Generator::Generator/Sequential[net]/ResBlock[11]/ret.67(Generator::nndct_elemwise_add_33)
        self.module_34 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/ResBlock[11]/LeakyReLU[leakyrelu]/ret.69(Generator::nndct_leaky_relu_34)
        self.module_35 = py_nndct.nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=[5, 5], stride=[2, 2], padding=[2, 2], output_padding=[1, 1], groups=1, bias=True, dilation=[1, 1]) #Generator::Generator/Sequential[net]/ConvTranspose2d[12]/ret.71(Generator::nndct_conv_transpose_2d_35)
        self.module_36 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/LeakyReLU[13]/ret.73(Generator::nndct_leaky_relu_36)
        self.module_37 = py_nndct.nn.Module('aten::_convolution_mode') #Generator::Generator/Sequential[net]/ResBlock[14]/Sequential[block]/Conv2d[0]/ret.75(Generator::aten__convolution_mode_37)
        self.module_38 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/ResBlock[14]/Sequential[block]/LeakyReLU[1]/ret.77(Generator::nndct_leaky_relu_38)
        self.module_39 = py_nndct.nn.Module('aten::_convolution_mode') #Generator::Generator/Sequential[net]/ResBlock[14]/Sequential[block]/Conv2d[2]/ret.79(Generator::aten__convolution_mode_39)
        self.module_40 = py_nndct.nn.Add() #Generator::Generator/Sequential[net]/ResBlock[14]/ret.81(Generator::nndct_elemwise_add_40)
        self.module_41 = py_nndct.nn.LeakyReLU(negative_slope=0.2, inplace=False) #Generator::Generator/Sequential[net]/ResBlock[14]/LeakyReLU[leakyrelu]/ret.83(Generator::nndct_leaky_relu_41)
        self.module_42 = py_nndct.nn.Conv2d(in_channels=64, out_channels=1, kernel_size=[11, 11], stride=[1, 1], padding=[5, 5], dilation=[1, 1], groups=1, bias=True) #Generator::Generator/Sequential[net]/Conv2d[15]/ret.85(Generator::nndct_conv2d_42)
        self.module_43 = py_nndct.nn.Tanh() #Generator::Generator/Sequential[net]/Tanh[16]/ret(Generator::nndct_tanh_43)
        self.net_2_block_0_weight = torch.nn.parameter.Parameter(torch.Tensor(64, 64, 3, 3))
        self.net_2_block_0_bias = torch.nn.parameter.Parameter(torch.Tensor(64,))
        self.net_2_block_2_weight = torch.nn.parameter.Parameter(torch.Tensor(64, 64, 3, 3))
        self.net_2_block_2_bias = torch.nn.parameter.Parameter(torch.Tensor(64,))
        self.net_5_block_0_weight = torch.nn.parameter.Parameter(torch.Tensor(128, 128, 3, 3))
        self.net_5_block_0_bias = torch.nn.parameter.Parameter(torch.Tensor(128,))
        self.net_5_block_2_weight = torch.nn.parameter.Parameter(torch.Tensor(128, 128, 3, 3))
        self.net_5_block_2_bias = torch.nn.parameter.Parameter(torch.Tensor(128,))
        self.net_8_block_0_weight = torch.nn.parameter.Parameter(torch.Tensor(256, 256, 3, 3))
        self.net_8_block_0_bias = torch.nn.parameter.Parameter(torch.Tensor(256,))
        self.net_8_block_2_weight = torch.nn.parameter.Parameter(torch.Tensor(256, 256, 3, 3))
        self.net_8_block_2_bias = torch.nn.parameter.Parameter(torch.Tensor(256,))
        self.net_11_block_0_weight = torch.nn.parameter.Parameter(torch.Tensor(128, 128, 3, 3))
        self.net_11_block_0_bias = torch.nn.parameter.Parameter(torch.Tensor(128,))
        self.net_11_block_2_weight = torch.nn.parameter.Parameter(torch.Tensor(128, 128, 3, 3))
        self.net_11_block_2_bias = torch.nn.parameter.Parameter(torch.Tensor(128,))
        self.net_14_block_0_weight = torch.nn.parameter.Parameter(torch.Tensor(64, 64, 3, 3))
        self.net_14_block_0_bias = torch.nn.parameter.Parameter(torch.Tensor(64,))
        self.net_14_block_2_weight = torch.nn.parameter.Parameter(torch.Tensor(64, 64, 3, 3))
        self.net_14_block_2_bias = torch.nn.parameter.Parameter(torch.Tensor(64,))

    @py_nndct.nn.forward_processor
    def forward(self, *args):
        output_module_0 = self.module_0(input=args[0])
        output_module_1 = self.module_1(input=args[1])
        output_module_0 = self.module_2(output_module_0)
        output_module_0 = self.module_3(input=output_module_0, shape=[4,100,8,8])
        output_module_1 = self.module_4(output_module_1)
        output_module_1 = self.module_5({'self': output_module_1,'dim': 1,'sizes': [16,8,8]})
        output_module_0 = self.module_6({'tensors': [output_module_0,output_module_1]})
        output_module_0 = self.module_7(output_module_0)
        output_module_0 = self.module_8(output_module_0)
        output_module_9 = self.module_9({'input': output_module_0,'weight': self.net_2_block_0_weight,'bias': self.net_2_block_0_bias,'stride': [1,1],'padding': 'same','dilation': [1,1],'groups': 1})
        output_module_9 = self.module_10(output_module_9)
        output_module_9 = self.module_11({'input': output_module_9,'weight': self.net_2_block_2_weight,'bias': self.net_2_block_2_bias,'stride': [1,1],'padding': 'same','dilation': [1,1],'groups': 1})
        output_module_9 = self.module_12(input=output_module_9, other=output_module_0, alpha=1)
        output_module_9 = self.module_13(output_module_9)
        output_module_9 = self.module_14(output_module_9)
        output_module_9 = self.module_15(output_module_9)
        output_module_16 = self.module_16({'input': output_module_9,'weight': self.net_5_block_0_weight,'bias': self.net_5_block_0_bias,'stride': [1,1],'padding': 'same','dilation': [1,1],'groups': 1})
        output_module_16 = self.module_17(output_module_16)
        output_module_16 = self.module_18({'input': output_module_16,'weight': self.net_5_block_2_weight,'bias': self.net_5_block_2_bias,'stride': [1,1],'padding': 'same','dilation': [1,1],'groups': 1})
        output_module_16 = self.module_19(input=output_module_16, other=output_module_9, alpha=1)
        output_module_16 = self.module_20(output_module_16)
        output_module_16 = self.module_21(output_module_16)
        output_module_16 = self.module_22(output_module_16)
        output_module_23 = self.module_23({'input': output_module_16,'weight': self.net_8_block_0_weight,'bias': self.net_8_block_0_bias,'stride': [1,1],'padding': 'same','dilation': [1,1],'groups': 1})
        output_module_23 = self.module_24(output_module_23)
        output_module_23 = self.module_25({'input': output_module_23,'weight': self.net_8_block_2_weight,'bias': self.net_8_block_2_bias,'stride': [1,1],'padding': 'same','dilation': [1,1],'groups': 1})
        output_module_23 = self.module_26(input=output_module_23, other=output_module_16, alpha=1)
        output_module_23 = self.module_27(output_module_23)
        output_module_23 = self.module_28(output_module_23)
        output_module_23 = self.module_29(output_module_23)
        output_module_30 = self.module_30({'input': output_module_23,'weight': self.net_11_block_0_weight,'bias': self.net_11_block_0_bias,'stride': [1,1],'padding': 'same','dilation': [1,1],'groups': 1})
        output_module_30 = self.module_31(output_module_30)
        output_module_30 = self.module_32({'input': output_module_30,'weight': self.net_11_block_2_weight,'bias': self.net_11_block_2_bias,'stride': [1,1],'padding': 'same','dilation': [1,1],'groups': 1})
        output_module_30 = self.module_33(input=output_module_30, other=output_module_23, alpha=1)
        output_module_30 = self.module_34(output_module_30)
        output_module_30 = self.module_35(output_module_30)
        output_module_30 = self.module_36(output_module_30)
        output_module_37 = self.module_37({'input': output_module_30,'weight': self.net_14_block_0_weight,'bias': self.net_14_block_0_bias,'stride': [1,1],'padding': 'same','dilation': [1,1],'groups': 1})
        output_module_37 = self.module_38(output_module_37)
        output_module_37 = self.module_39({'input': output_module_37,'weight': self.net_14_block_2_weight,'bias': self.net_14_block_2_bias,'stride': [1,1],'padding': 'same','dilation': [1,1],'groups': 1})
        output_module_37 = self.module_40(input=output_module_37, other=output_module_30, alpha=1)
        output_module_37 = self.module_41(output_module_37)
        output_module_37 = self.module_42(output_module_37)
        output_module_37 = self.module_43(output_module_37)
        return output_module_37
